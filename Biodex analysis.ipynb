{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4372f09a-fb0b-40a4-9b46-3009220118bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from ipyfilechooser import FileChooser\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sonpy import lib as sp\n",
    "from scipy.signal import butter, filtfilt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm  # For progress bars\n",
    "# Step 1: Modularize the Code\n",
    "def parse_text_marks(text_marks, time_base, sample_rate):\n",
    "    indices, texts, categories = [], [], []\n",
    "    for mark in text_marks:\n",
    "        indices.append(int(mark.Tick * time_base * sample_rate))\n",
    "        text = mark.GetString().upper()\n",
    "        texts.append(text)\n",
    "        categories.append('PUSH' if 'PUSH' in text else 'PULL' if 'PULL' in text else 'UNKNOWN')\n",
    "    return indices, texts, categories\n",
    "\n",
    "def read_smr_file(file_path):\n",
    "    MyFile = sp.SonFile(str(file_path), True)\n",
    "    all_channels = {MyFile.GetChannelTitle(i): i for i in range(MyFile.MaxChannels()) if MyFile.ChannelType(i) != sp.DataType.Off}\n",
    "    time_base = MyFile.GetTimeBase()\n",
    "    channel_data = {}\n",
    "    for name, i in all_channels.items():\n",
    "        data_type = MyFile.ChannelType(i)\n",
    "        size = MyFile.ChannelBytes(i)\n",
    "        item_size = MyFile.ItemSize(i)\n",
    "        scale = MyFile.GetChannelScale(i) / 6553.6\n",
    "        offset = MyFile.GetChannelOffset(i)\n",
    "        if data_type == sp.DataType.Adc:\n",
    "            data = np.array(sp.SonFile.ReadInts(MyFile, i, size // item_size, 0)) * scale + offset\n",
    "        elif data_type == sp.DataType.TextMark:\n",
    "            data = np.array(sp.SonFile.ReadTextMarks(MyFile, i, size // item_size, 0))\n",
    "        else:\n",
    "            continue\n",
    "        channel_data[name] = data\n",
    "    return channel_data, time_base\n",
    "\n",
    "def process_emg(data, fs, band=(20, 450), window_size=0.3):\n",
    "    filtered = bandpass_filter(data, band[0], band[1], fs)\n",
    "    rectified = np.abs(filtered)\n",
    "    smoothed = np.convolve(rectified, np.ones(int(window_size * fs)) / (window_size * fs), mode='same')\n",
    "    return smoothed\n",
    "\n",
    "def low_pass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter(order, cutoff / (0.5 * fs), btype='low')\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    b, a = butter(order, [lowcut / (0.5 * fs), highcut / (0.5 * fs)], btype='band')\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def process_trials(trial_indices, trial_type, adjusted_indices, adjusted_texts):\n",
    "    peak_emg_results = []\n",
    "    for idx in trial_indices:\n",
    "        first_index = adjusted_indices[idx]\n",
    "        text = adjusted_texts[idx]\n",
    "        \n",
    "        # Define the time window for the plot\n",
    "        seconds_before, seconds_after = 1, 5\n",
    "        \n",
    "        # Calculate the sample indices for the time window\n",
    "        start_index = max(first_index - seconds_before * sample_rate, 0)\n",
    "        end_index = min(first_index + seconds_after * sample_rate, len(channel_data['MZ']))\n",
    "        \n",
    "        # Extract data for the time window\n",
    "        time_window = np.arange(start_index, end_index) / sample_rate\n",
    "        MZ_window = channel_data['MZ'][start_index:end_index]\n",
    "        EMG1_window = channel_data['EMG1'][start_index:end_index]\n",
    "        EMG2_window = channel_data['EMG2'][start_index:end_index]\n",
    "        EMG3_window = channel_data['EMG3'][start_index:end_index]\n",
    "        \n",
    "        # Ensure all arrays have the same length\n",
    "        min_length = min(len(time_window), len(MZ_window), len(EMG1_window), len(EMG2_window), len(EMG3_window))\n",
    "        time_window = time_window[:min_length]\n",
    "        MZ_window = MZ_window[:min_length]\n",
    "        EMG1_window = EMG1_window[:min_length]\n",
    "        EMG2_window = EMG2_window[:min_length]\n",
    "        EMG3_window = EMG3_window[:min_length]\n",
    "        \n",
    "        # Process and analyze data\n",
    "        MZ_filtered = low_pass_filter(MZ_window, cutoff_frequency, sample_rate)\n",
    "        mz_baseline = np.mean(channel_data['MZ'][start_index:first_index])\n",
    "        MZ_change = MZ_filtered - mz_baseline\n",
    "        max_change_value = np.max(np.abs(MZ_change))\n",
    "        max_change_index = np.argmax(np.abs(MZ_change))\n",
    "        max_value = mz_baseline + max_change_value\n",
    "        max_change_time = time_window[max_change_index]\n",
    "\n",
    "        EMG1_processed = process_emg(EMG1_window, sample_rate)\n",
    "        EMG2_processed = process_emg(EMG2_window, sample_rate)\n",
    "        EMG3_processed = process_emg(EMG3_window, sample_rate)\n",
    "\n",
    "        initial_window_size = int(2 * sample_rate)\n",
    "        emg1_baseline = np.mean(EMG1_processed[:initial_window_size])\n",
    "        emg2_baseline = np.mean(EMG2_processed[:initial_window_size])\n",
    "        emg3_baseline = np.mean(EMG3_processed[:initial_window_size])\n",
    "\n",
    "        peak_analysis_start_index = max(max_change_index - int(0.05 * sample_rate), 0)\n",
    "        peak_analysis_end_index = min(max_change_index + int(0.05 * sample_rate), len(EMG1_processed))\n",
    "\n",
    "        peak_EMG1 = np.max(EMG1_processed[peak_analysis_start_index:peak_analysis_end_index])\n",
    "        peak_EMG2 = np.max(EMG2_processed[peak_analysis_start_index:peak_analysis_end_index])\n",
    "        peak_EMG3 = np.max(EMG3_processed[peak_analysis_start_index:peak_analysis_end_index])\n",
    "\n",
    "        delta_EMG1 = peak_EMG1 - emg1_baseline\n",
    "        perc_change_EMG1 = (delta_EMG1 / emg1_baseline) * 100 if emg1_baseline != 0 else np.nan\n",
    "        delta_EMG2 = peak_EMG2 - emg2_baseline\n",
    "        perc_change_EMG2 = (delta_EMG2 / emg2_baseline) * 100 if emg2_baseline != 0 else np.nan\n",
    "        delta_EMG3 = peak_EMG3 - emg3_baseline\n",
    "        perc_change_EMG3 = (delta_EMG3 / emg3_baseline) * 100 if emg3_baseline != 0 else np.nan\n",
    "        \n",
    "        peak_emg_results.append({\n",
    "            'trial_type': trial_type,\n",
    "            'trial_number': idx + 1,\n",
    "            'MZ_change': f\"Delta: {max_change_value:.2f} (Baseline: {mz_baseline:.2f}, Max: {max_value:.2f}, {max_change_value / mz_baseline * 100:.2f}%)\",\n",
    "            'EMG1 (Soleus)': f\"Delta: {delta_EMG1:.5f} (Baseline: {emg1_baseline:.5f}, Max: {peak_EMG1:.5f}, {perc_change_EMG1:.5f}%)\",\n",
    "            'EMG2 (Tibialis Anterior)': f\"Delta: {delta_EMG2:.5f} (Baseline: {emg2_baseline:.5f}, Max: {peak_EMG2:.5f}, {perc_change_EMG2:.5f}%)\",\n",
    "            'EMG3 (Gastrocnemius)': f\"Delta: {delta_EMG3:.5f} (Baseline: {emg3_baseline:.5f}, Max: {peak_EMG3:.5f}, {perc_change_EMG3:.5f}%)\",\n",
    "            'time_window': time_window,\n",
    "            'MZ_window': MZ_window,\n",
    "            'MZ_filtered': MZ_filtered,\n",
    "            'EMG1_processed': EMG1_processed,\n",
    "            'EMG2_processed': EMG2_processed,\n",
    "            'EMG3_processed': EMG3_processed,\n",
    "            'mz_baseline': mz_baseline,\n",
    "            'max_change_time': max_change_time,\n",
    "            'peak_analysis_start_index': peak_analysis_start_index,\n",
    "            'peak_analysis_end_index': peak_analysis_end_index,\n",
    "            'emg1_baseline': emg1_baseline,\n",
    "            'emg2_baseline': emg2_baseline,\n",
    "            'emg3_baseline': emg3_baseline\n",
    "        })\n",
    "    \n",
    "    return peak_emg_results\n",
    "\n",
    "\n",
    "def print_results_table(results):\n",
    "    if not results:\n",
    "        print(\"No results to display.\")\n",
    "        return\n",
    "    \n",
    "    data = []\n",
    "    for result in results:\n",
    "        data.append({\n",
    "            'Trial Type': result['trial_type'],\n",
    "            'Trial Number': result['trial_number'],\n",
    "            'MZ Change': result['MZ_change'],\n",
    "            'EMG1 (Soleus)': result['EMG1 (Soleus)'],\n",
    "            'EMG2 (Tibialis Anterior)': result['EMG2 (Tibialis Anterior)'],\n",
    "            'EMG3 (Gastrocnemius)': result['EMG3 (Gastrocnemius)']\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df.to_string(index=False))\n",
    "    return df  # Return the dataframe for potential export\n",
    "\n",
    "def plot_trials(results, trial_type, dynamic=False):\n",
    "    if not results:\n",
    "        print(f\"No {trial_type} trials to plot.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(18, 12))\n",
    "    for i, result in enumerate(results[:3]):\n",
    "        plt.subplot(3, 2, i * 2 + 1)\n",
    "        plt.plot(result['time_window'], result['MZ_window'], label='MZ (Original)', alpha=0.5)\n",
    "        plt.plot(result['time_window'], result['MZ_filtered'], label='MZ (Filtered)', linestyle='--', alpha=0.8)\n",
    "        plt.axhline(y=result['mz_baseline'], color='g', linestyle='--', label='Baseline')\n",
    "        plt.axvline(x=result['max_change_time'], color='r', linestyle='--', label=f'Max Change: {np.max(np.abs(result[\"MZ_window\"] - result[\"mz_baseline\"])):.2f}')\n",
    "        plt.title(f'MZ Channel (Torque) - {trial_type} Trial {i+1}')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(3, 2, i * 2 + 2)\n",
    "        plt.plot(result['time_window'], result['EMG1_processed'], label='Soleus (EMG1)', color='blue')\n",
    "        plt.plot(result['time_window'], result['EMG2_processed'], label='Tibialis Anterior (EMG2)', color='orange')\n",
    "        plt.plot(result['time_window'], result['EMG3_processed'], label='Gastrocnemius (EMG3)', color='green')\n",
    "        plt.axhline(y=result['emg1_baseline'], color='blue', linestyle=':', label='EMG1 Baseline')\n",
    "        plt.axhline(y=result['emg2_baseline'], color='orange', linestyle=':', label='EMG2 Baseline')\n",
    "        plt.axhline(y=result['emg3_baseline'], color='green', linestyle=':', label='EMG3 Baseline')\n",
    "        plt.axvline(x=result['time_window'][result['peak_analysis_start_index']], color='g', linestyle='--', label='Peak Analysis Window Start')\n",
    "        plt.axvline(x=result['time_window'][result['peak_analysis_end_index']-1], color='b', linestyle='--', label='Peak Analysis Window End')\n",
    "        plt.title(f'EMG Channels (Processed) - {trial_type} Trial {i+1}')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    pdf_path = os.path.join(original_file_dir, f\"{original_file_name}-plot.pdf\")\n",
    "    plt.savefig(pdf_path, format='pdf')  # Save as PDF\n",
    "    if dynamic:\n",
    "        plt.ion()\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Step 2: Add Interactive Widgets for Control\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "file_path_text = widgets.Text(value='', placeholder='File path will be displayed here', description='File Path:', disabled=True)\n",
    "output = widgets.Output()\n",
    "adjusted_indices, adjusted_texts, deleted_marks, categories = [], [], [], []\n",
    "\n",
    "def update_file_path(chooser):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        file_path = chooser.selected\n",
    "        if file_path:\n",
    "            file_path_text.value = file_path\n",
    "            global channel_data, time_base, indices, texts, categories, sample_rate, cutoff_frequency, original_file_name, original_file_dir\n",
    "            sample_rate = 2000  # Hz\n",
    "            cutoff_frequency = 50  # Low-pass filter cutoff frequency for MZ\n",
    "            channel_data, time_base = read_smr_file(file_path)\n",
    "            indices, texts, categories = parse_text_marks(channel_data['TextMark'], time_base, sample_rate)\n",
    "            \n",
    "            # Properly initialize the adjusted indices, texts, and deleted marks lists\n",
    "            adjusted_indices = indices.copy()\n",
    "            adjusted_texts = texts.copy()\n",
    "            deleted_marks = [False] * len(indices)\n",
    "            \n",
    "            # Get the original file name and directory\n",
    "            original_file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            original_file_dir = os.path.dirname(file_path)\n",
    "            \n",
    "            print(f\"File loaded: {file_path}\")\n",
    "            print(\"Text marks available for selection.\")\n",
    "\n",
    "file_chooser.register_callback(update_file_path)\n",
    "\n",
    "def plot_torque(time_window, MZ_window, idx, text, plot_output, removed=False):\n",
    "    with plot_output:\n",
    "        clear_output(wait=True)\n",
    "        if time_window is not None and MZ_window is not None:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(time_window, MZ_window, label=f'{text}')\n",
    "            plt.axvline(x=idx / sample_rate, color='r', linestyle='--')\n",
    "            if removed:\n",
    "                plt.scatter([idx / sample_rate], [np.max(MZ_window)], color='red', marker='x', s=100, label='Removed')\n",
    "            plt.title(f'Torque Data Around Text Mark: {text}')\n",
    "            plt.xlabel('Time (s)')\n",
    "            plt.ylabel('Torque (MZ)')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "def update_plot(change, idx, text, adjust_mark, remove_mark, plot_output, i):\n",
    "    if remove_mark.value:\n",
    "        deleted_marks[i] = True\n",
    "        plot_torque(None, None, idx, text, plot_output, removed=True)\n",
    "        return\n",
    "    else:\n",
    "        deleted_marks[i] = False\n",
    "    \n",
    "    seconds_before = 2\n",
    "    seconds_after = 3\n",
    "    \n",
    "    start_index = max(int(adjust_mark.value * sample_rate) - seconds_before * sample_rate, 0)\n",
    "    end_index = min(int(adjust_mark.value * sample_rate) + seconds_after * sample_rate, len(channel_data['MZ']))\n",
    "    \n",
    "    time_window = np.arange(start_index, end_index) / sample_rate\n",
    "    MZ_window = channel_data['MZ'][start_index:end_index]\n",
    "    \n",
    "    adjusted_indices[i] = int(adjust_mark.value * sample_rate)\n",
    "    \n",
    "    plot_torque(time_window, MZ_window, int(adjust_mark.value * sample_rate), text, plot_output)\n",
    "\n",
    "def plot_torque_around_text_marks():\n",
    "    with output:\n",
    "        clear_output()\n",
    "        seconds_before = 10\n",
    "        seconds_after = 10\n",
    "        \n",
    "        global adjusted_indices, adjusted_texts, deleted_marks, categories\n",
    "        adjusted_indices = indices.copy()\n",
    "        adjusted_texts = texts.copy()\n",
    "        deleted_marks = [False] * len(indices)\n",
    "        \n",
    "        for i, (idx, text) in enumerate(zip(indices, texts)):\n",
    "            start_index = max(idx - seconds_before * sample_rate, 0)\n",
    "            end_index = min(idx + seconds_after * sample_rate, len(channel_data['MZ']))\n",
    "            \n",
    "            time_window = np.arange(start_index, end_index) / sample_rate\n",
    "            MZ_window = channel_data['MZ'][start_index:end_index]\n",
    "            \n",
    "            plot_output = widgets.Output()\n",
    "            display(plot_output)\n",
    "            \n",
    "            adjust_mark = widgets.FloatSlider(\n",
    "                value=idx / sample_rate,\n",
    "                min=(start_index / sample_rate),\n",
    "                max=(end_index / sample_rate),\n",
    "                step=0.001,\n",
    "                description=f'Adjust {text}:',\n",
    "                continuous_update=False\n",
    "            )\n",
    "            \n",
    "            remove_mark = widgets.Checkbox(value=False, description='Remove this mark', disabled=False)\n",
    "            \n",
    "            display(adjust_mark, remove_mark)\n",
    "            \n",
    "            adjust_mark.observe(\n",
    "                lambda change, i=i, idx=idx, text=text, adjust_mark=adjust_mark, remove_mark=remove_mark, plot_output=plot_output:\n",
    "                update_plot(change, idx, text, adjust_mark, remove_mark, plot_output, i),\n",
    "                names='value'\n",
    "            )\n",
    "            \n",
    "            remove_mark.observe(\n",
    "                lambda change, i=i, idx=idx, text=text, adjust_mark=adjust_mark, remove_mark=remove_mark, plot_output=plot_output:\n",
    "                update_plot(change, idx, text, adjust_mark, remove_mark, plot_output, i),\n",
    "                names='value'\n",
    "            )\n",
    "            \n",
    "            update_plot(None, idx, text, adjust_mark, remove_mark, plot_output, i)\n",
    "\n",
    "plot_torque_button = widgets.Button(description=\"Plot Torque Around Text Marks\")\n",
    "plot_torque_button.on_click(lambda b: plot_torque_around_text_marks())\n",
    "\n",
    "process_button = widgets.Button(description=\"Process and Plot Data\")\n",
    "\n",
    "save_button = widgets.Button(description=\"Save Results as CSV\")\n",
    "\n",
    "selected_trials_label = widgets.Label(value=\"Selected PUSH: 0 | PULL: 0\")\n",
    "\n",
    "def update_selected_trials_count():\n",
    "    selected_categories = [categories[i] for i in range(len(categories)) if not deleted_marks[i]]\n",
    "    push_count = selected_categories.count('PUSH')\n",
    "    pull_count = selected_categories.count('PULL')\n",
    "    selected_trials_label.value = f\"Selected PUSH: {push_count} | PULL: {pull_count}\"\n",
    "\n",
    "def process_and_plot_data(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_indices = [adjusted_indices[i] for i in range(len(adjusted_indices)) if not deleted_marks[i]]\n",
    "        selected_texts = [adjusted_texts[i] for i in range(len(adjusted_texts)) if not deleted_marks[i]]\n",
    "        selected_categories = [categories[i] for i in range(len(categories)) if not deleted_marks[i]]\n",
    "        \n",
    "        if not selected_indices:\n",
    "            print(\"No valid text marks selected. Please review your selections.\")\n",
    "            return\n",
    "        \n",
    "        push_indices = [i for i, t in enumerate(selected_categories) if t == 'PUSH']\n",
    "        pull_indices = [i for i, t in enumerate(selected_categories) if t == 'PULL']\n",
    "        \n",
    "        # Progress bar for data processing\n",
    "        with tqdm(total=len(push_indices) + len(pull_indices)) as pbar:\n",
    "            push_results = process_trials(push_indices, 'PUSH', selected_indices, selected_texts)\n",
    "            pbar.update(len(push_indices))\n",
    "            pull_results = process_trials(pull_indices, 'PULL', selected_indices, selected_texts)\n",
    "            pbar.update(len(pull_indices))\n",
    "        \n",
    "        plot_trials(push_results, 'PUSH')\n",
    "        plot_trials(pull_results, 'PULL')\n",
    "        \n",
    "        # Print and save results\n",
    "        push_df = print_results_table(push_results)\n",
    "        pull_df = print_results_table(pull_results)\n",
    "        global combined_df\n",
    "        combined_df = pd.concat([push_df, pull_df], ignore_index=True)\n",
    "        update_selected_trials_count()\n",
    "\n",
    "def save_results(b):\n",
    "    if combined_df is not None:\n",
    "        save_path = os.path.join(original_file_dir, f\"{original_file_name}-biodexresults.csv\")\n",
    "        combined_df.to_csv(save_path, index=False)\n",
    "        with output:\n",
    "            print(f\"Results saved as '{save_path}'\")\n",
    "\n",
    "process_button.on_click(process_and_plot_data)\n",
    "save_button.on_click(save_results)\n",
    "\n",
    "display(file_chooser, file_path_text, plot_torque_button, output, process_button, save_button, selected_trials_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d4b93b9-6c56-402c-bb5c-9c5309788360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4177a7f40be24803960055408d7c63ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='C:\\Users\\anehrujee\\Desktop\\biodex', filename='', title='', show_hidden=False, select_desc='S…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0b7d7d463d405e9d94a2e5eef90b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='File Path:', disabled=True, placeholder='File path will be displayed here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53308cf939a94416a23f3c4315fcadc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Plot Torque Around Text Marks', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7579fb4b16424b931b2531ef3a4235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b21c8d9be94a52901ff6dff0c46be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Process and Plot Data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42922201a003422a9b15242f6c961182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Save Results as CSV', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f26f73f1de48d8a38f25cac1bdf9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Selected PUSH: 0 | PULL: 0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da7f6d-7280-4137-9768-b5f7d91fe51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a117c9b-3184-46ff-ae0e-cd500dcc7764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
